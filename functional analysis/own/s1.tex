\chapter{Prep work}
We will start from the beginning and take baby steps. It's going to be okay.


An algebra is a vector space (with addition and scalar multiplication, usually over $\R, \C$), with an extra multiplication operation such that it is associative, and distributive. Then a normed algebra is an algebra with a sub-multiplicative norm, such that for all $a,b\in\mathcal{A}$, we have
\begin{equation*}
    \|ab\|\leq\|a\|\|b\|
\end{equation*}
\begin{comment}
    We don't know how to multiply two vectors if we are just given a vector space. Hence giving it a norm gives us the ability to multiply. Note such multiplication is only sub-multiplicative.
\end{comment}

A Banach algebra is a normed algebra that is complete under the metric induced by the norm. And we can form a Banach algebra by starting with a normed algebra and form its completion and by uniform continuity of addition and multiplicatoin extend to the completion of the algebra to form a Banach algebra.

We will begin with some important examples of Banach algebras.
Let $X$ be a compact topological space, and let $C(X)$ be the space of continuous functions, equip it with $\|\cdot\|_{L^\infty}$ norm, then $(C(X), \|\cdot\|_{L^\infty})$ is a Banach algebra. Similarly, if $X$ is only locally compact, then $C_b(X)$, the space of bounded continuous functions under the $\|\cdot\|_{L^\infty}$ norm is also a Banach algebra.

\begin{proposition}
    Multiplication is continuous in Banach algebras.
\end{proposition}
\begin{proof}
    Multiplication $\cdot: \mathcal{A}\times\mathcal{A}\to\mathcal{A}$, hence if we have $x_n, y_n$ such that $x_n\to x, y_n\to y$, then we have
    \begin{equation*}
        \|x_ny_n-xy\|\leq\|x_n-x\|\|y_n\|+\|x\|\|y_n-y\|<\epsilon
    \end{equation*}
    Hence multiplication is continuous.
\end{proof}

\begin{definition}[Unital Banach algebra and invertibility] 
    A Banach algebra (let's repeat, a complete vector space with addition, scalar multiplicatin, and multiplication such that the norm is sub-multiplicative) is called unital if there exists a multiplicative inverse.

    An element $a\in\mathcal{A}$ is called invertible if there exists an element $a^{-1}\in\mathcal{A}$ such that
    \begin{equation*}
        aa^{-1}=a^{-1}a=e
    \end{equation*}
\end{definition}

Another important example is that let $X$ be a Banach space, and the space of all bounded/continuous operators on $X$, denoted by $\mathcal{B}(X)$ is a Banach algebra with the operator norm. Any closed subalgebra of $B(X)$ is also Banach.

If $X$ is a Hilbert space, then we also have the operation of taking adjoints, namely $\|T\|=\|T^*\|$.

\begin{definition}
    A $C^*$ algebra is a closed subalgebra of the space of bounded (equivalently) functions defined on a Hilbert space, $\mathcal{B}(\mathcal{H})$. 
\end{definition}
\begin{remark}
    The space of continuous/bdd operators on a Hilbert space, under the operator norm, then closed under the norm topology and taking adjoints of the operators. On wikipedia, C* algebra is defined to be a Banach algebra equipped with an involution that acts like a adjoint.
\end{remark}


One of the goals of this course is to develop the following theorem.
\begin{theorem}
    Let $\mathcal{A}$ be a commutative $C^*$-algebra of $\mathcal{B}(\mathcal{H})$, then $\mathcal{A}$ is isometrically and *-algebraically isomorphic to some $C(X)$, where $X$ is some locally compact space.
\end{theorem}


We will mostly follow the lecture and the previous lecture notes.
\begin{definition}[Algebra homomorphism]
    An algebra homomorphism is a homomorphism between two algebras. For example, consider $X$ a compact space, and $C(X)$ the space of continuous functions, hence if we define the evalutation map as follows:
    \begin{equation*}
        \varphi_x(f)=f(x)
    \end{equation*}
    This is an algebra homomorphism between $C(X)$ and $(\C)$. Namely, the homomorphism property is justified as: (under both addition and multiplication)
    \begin{equation*}
        \varphi_x(f+g)=f+g(x)=f(x)+g(x)=\varphi_x(f)+\varphi_x(g)
    \end{equation*}
    \begin{equation*}
        \varphi_x(fg)=(fg)(x)=f(x)g(x)=\varphi_x(f)\varphi_x(g)
    \end{equation*}
    And of course, same thing follows for scalar multiplication. 
\end{definition}
\begin{remark}
    We need to check all three conditions to make sure such $\varphi$ preserves the structures between the algebras.
\end{remark}

An algebra homomorphism is called unital if if maps the (multiplicative identity) unity to unity. In the above example, a unital homomorphism would be $\varphi(1)=1$, where the left 1 is the constant 1 function, and the right 1 is the number.



Now we will introduce the proposition that every multiplicative linear functional on $C(X)$. Note we can use algebra homomorphism and multiplicative linear functional synonomously on $C(X)$, hence they entail the same information.
\begin{proposition}
    Let $\varphi$ be a multiplicative linear functional on $C(X)$, i.e. a nontrivial algebra homomorphism, then $\varphi(f)=f(x_0)$ for some $x_0\in X$. In other words, a multiplicative linear functional always takes this form.
\end{proposition}
\begin{proof}
    It suffices to show the following lemma: 
    \begin{lemma}
        There exists $x_0$ such that if $\varphi(f)=0$, then we have $f(x_0)=0$.
    \end{lemma}
    We will first show how the lemma implies $\varphi(f)=f(x_0)$. Consider the function $f-\varphi(f)\cdot 1$, then we know
    \begin{equation*}
        \varphi(f-\varphi(f)\cdot 1)=0
    \end{equation*}
    Then there exists $x_0$ such that $f(x_0)-\varphi(f)=0$, this gives $\varphi(f)=f(x_0)$.  

    Now we prove the lemma.
    \begin{proof}
        Our claim is that there exists $x_0$ such that if $\varphi(f)=0$, then we have $f(x_0)=0$. Assume the contrary, which states for all $x$, there exists an $f_x$ such that $\varphi(f_x)=0$, but $f(x)\neq 0$. We define a nonnegative function $g_x=f_x\overline{f_x}$. And by multiplicativity, we have $\varphi(g_x)=0$. We now note that because $g$ is continuous, in a small nbd of $x$, denoted by $O_x$, we have $g(y)>0$ for all $y\in O_x$.
        
        Now using compactness, we can write $X$ as a finite union of small neighborhoods $X=\bigcup_{j=1}^nO_{x_j}$, and define
        \begin{equation*}
            g=g_{x_1}+...+g_{x_n}
        \end{equation*}
        Then for each $y\in X$, $y\in O_{x_j}$ for some $j$, hence $g(y)>0$ for all $y\in X$. This implies that $g$ is invertible hence we have
        \begin{equation*}
            \varphi(g\cdot 1/g)=1
        \end{equation*}
        This contradicts with the fact that $\varphi(g)=0$. And we are done.
    \end{proof}
\end{proof}
\qed

Hence we have the following corollary.
\begin{corollary}
    Let $X$ be compact, and $C(X)$ the space of continuous functions, then $\varphi$ is a multiplicative linear functional (i.e. a algebra homomorphism with $\C$) if and only if it is a point evaluation.
\end{corollary}

\begin{definition}[$\widehat{\mathcal{A}}$]
    Given a unital commutative (or Banach) algebra, for example, $C(X)$ with $\|\cdot\|_{L^\infty}$, we define the set of unital homomorphisms, i.e., nonzero unital multiplicative linear functionals on $\mathcal{A}$ as $\widehat{\mathcal{A}}$.
\end{definition}
\begin{proposition}
    If $\mathcal{A}$ is a unital algebra, then for $\varphi\in\widehat{\mathcal{A}}$, we have $\|\varphi\|=1$
\end{proposition}
\begin{proof}
    We have
    \begin{equation*}
        \|\varphi\|=\sup\{|\varphi(f)|:\|f\|_{L^\infty}=1 \}
    \end{equation*}
    Because $|\varphi(f)|=|f(x_0)|$ for some $x_0$, we always have $\|\varphi\|\leq 1$, but with the unity, we have $|\varphi(e)|=1$, and taking the sup we have $\|\varphi\|=1$.
\end{proof}
\qed





