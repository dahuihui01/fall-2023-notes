\chapter{Lecture 1}
Here we go.

\subsection{Course Overview and Logistics}
Some administrative things.
OH are Monday, Fridays 1:45 to 2:45, Wednesdays 12:45-1:45 in Evans 811.

\textbf{Textbook}: an introduction to functional analysis by Conway.
We will be talking about operators on Hilbert spaces, and more generally, Banach spaces, and Frechet spaces (defined by a countable numer of seminomrs).

\begin{remark}
    Let $\mathcal{H}$ be a Hilbert space, then the dual space $\mathcal{H}^*$ is itself. $\mathcal{H}=\mathcal{H}^*$.    
    Hilbert spaces are the best spaces to work with. They are self-dual, and identified with themslves.
\end{remark}
Then in the next section, we will look at groups, motivated by their actions on Banach spaces, connected with Fourier transforms. 


\subsection{Motivation}
Let $X$ be a compact Hausdorff space. Let $C(X)=\{f:X\to\R, f \text{ continuous}\} $ be the algebra of continuous functions on $X$ mapping in to $\R$ or $\mathbb{C}$.
Define the norm as the sup norm $\|\cdot\|_{L^\infty}$.

We will develop the spectral theorem of operators on the Hilbert space, i..e self-adjoint operators can be diagonalized.

If $T$ is a self-adjoint operator on a Hilbert space, then we take the product of $T$ (polynomials of $T$), let $C^*(T, I_\mathcal{H})$ be the sub-algebra of operators generated by $T$ and $I$ the identity operator, then take the closure, i.e. making it closed in the operator norm.

\begin{remark}
    The $*$ is to remind us, $T$ is self-adjoint and when you take the adjoint and generate with it, it gets back into the same space.
\end{remark}

\begin{proposition}
    We have the next two algebra isomorphic to each other.
    \begin{equation}
        C^*(T, I_\mathcal{H})\cong C(X)
    \end{equation}
\end{proposition}
This is what we are aiminig for. We can generalize this even further to finitely many self-adjoint operators, in some sense, we are diagonalizing finitely many operators at the same time. If $T_1,..., T_n$ is a collection of self-adjoint operators on $\mathcal{H}$, and such all commute with each other, then we also have
\begin{equation}
    C^*(T_1,..., T_n, I_\mathcal{H})\cong C(X)
\end{equation}

\subsection{Groups}

Let $G$ be a group, $B$ be a Banach space, for example, groups of automorphisms. Let
\begin{equation*} 
    Aut(B)=\{T:  T \text{is isometric, onto, invertible on } B\}
\end{equation*}

\begin{definition}
    Suppose that $\alpha$ is a group homomorphisms, and $\alpha: G\to Aut(B)$, is called a representation on $B$ or an action of the group $G$ on $B$.
\end{definition}


Then we can consider the subalgebra $\mathcal{L}(B)$, consisting of the bounded linear operators on $B$, generated by
\begin{equation*}
    \{\alpha_x:x\in G\}
\end{equation*}
\begin{remark}
    The identity on $G$ should be mapped into the identity operator on $B$, hence no need to include it.
\end{remark}

Elements of the form $\Sigma_{z_x}\alpha_x, z_x\in\mathbb{C}$, (where $\Sigma$ is a finite sum.)

Let's introduce,
$f\in C_c(G)$ are functions with compact support and in discrete groups, imply they are of finite support.

\begin{equation*}
    \sum_{x\in G}f(x)\alpha_x=\alpha_f
\end{equation*}
note for except finitely many $x$, $f(x)=0$.

Let $f,g\in C_c(G)$, then for 
\begin{equation*}
    \alpha_f\alpha_g=(\sum f(x)\alpha_x)(\sum g(y)\alpha_y)=\sum_{x,y}f(x)g(y)\alpha_x\alpha_y=\sum_{x,y}f(x)g(y)\alpha_{xy}
\end{equation*}
The last inequality follows from $\alpha$ being a group homomorphism. And the sums are finite hence are able to exchange the orders.
We further have,
\begin{equation*}
    \alpha_f\alpha_g=\sum_x\sum_yf(x)g(x^{-1}y)\alpha_y=\sum (f\ast g)(y)\alpha_y
\end{equation*}
where we define $f\ast g(y)=\sum f(x)g(x^{-1}y)$ as the convolution operator.


We get
\begin{equation*}
    \alpha_f\alpha_g=\alpha_{f\ast g}
\end{equation*}
This is how we define convolution on $C_c(G)$
Notice we have, by $\|\alpha_x\|=1$,
\begin{equation*}
    \|\alpha_f\|=\|\sum f(x)\alpha_x\|\leq\sum|f(x)|\|\alpha_x\|=\sum|f(x)|=l^1(f)=\|f\|_{l^1}
\end{equation*}
It is therefore, easy to check

\begin{equation*}
    \|f\ast g\|_{l^1}\leq\|f\|_{l^1}\|g\|_{l^1}
\end{equation*}
We get $l^1(G)$ is an algebra with ??

For $G$ commutative, it is easily connected with the Fourier transform.

Consider $l^2(G)$ with the counting measure on the group. For $x\in G$, let $\xi\in l^2(G)$ define $\alpha_x\xi(y)=\xi(x^{-1}y), \alpha_x$ being unitary.
$l^1(G)$ acts on operators in $l^2(G)$ via $\alpha$.


If $G$ is commutative, then we have
\begin{equation*}
    \overline{\alpha_{l^1(G)}}\cong C(X)
\end{equation*}
where $X$ is some compact space.
Note that $C_c(G)$ operators on $l^2(G)$, and $\|\alpha_f\|\leq\|f\|_{l^1}$.

\newpage
\section{Lecture 2}
Let's do some math.

Let $X$ be a Hausdorff compact space, and let $C(X)$ denote the space of continuous functions defined on $X$. This is an algebra. You can multiply them, associatively and commutatively. We equip it with a norm $\|\cdot\|_{L^\infty}$. Note $X$, by assumption, is a normal space, you could have continuous functions mapped to 1 on one subset, 0 to the other subset. Hence there are many elements from $C(X)$.

\begin{definition}[Normed Algebra]
    Let $\mathcal{A}$ be an algebra on $\R$ or $\mathbb{C}$, is a normed algebra if it has a norm $\| \|$, as a vector space, such that for for $a,b\in\mathcal{A}$, we have
    \begin{equation*}
        \|ab\|\leq\|a\|\|b\|
    \end{equation*}
    The above is called submultiplicity.
\end{definition}
\begin{definition}[Banach Algebra]
    A Banach Algebra is a normed algebra that is complete in the metric space from the norm.
\end{definition}


Given $x\in X$, define $\varphi_x: C(X)$ the evaluation map such that
\begin{equation*}
    \varphi_x(f)=f(x)
\end{equation*}

$\varphi_x$ is an algebra homomorphisms between $C(X)\to\R$ or $C(X)\to\mathbb{C}$. This simply implies
\begin{equation*}
    \varphi_x(f+g)=(f+g)(x)=f(x)+g(x), \varphi_x(fg)=(fg)(x)=f(x)g(x)
\end{equation*}

We now make the note that, $C(X)$ has an identity element, which is the constant function $1$, under multiplication. Hence $C(X)$ is a unital algebra. Note that $\varphi_x$ defined above is a unital homomorphism, meaning that it sends identity to identity.

Note $\varphi_x$ is also a multiplicative linear functional, also unital.

\begin{proposition}
    Every multiplicative linear functional on $C(X)$ is of the form $\varphi_x$ for some $x\in X$.
\end{proposition}
\begin{proof}
    Main Claim: given a multiplicative linear functional $\varphi$, there exists a point $x_0$ and if we have some $f\in C(X)$, we have $\varphi(f)=0$, then we have $f(x_0)=0$. To prove this claim, we need compactness. Suppose the contrary of the claim. Suppose that for each $x\in X$, there is an $f_x\in C(X)$ such that $f(x)\neq 0$, but $\varphi(f)=0$.

    Set $g_x=\overline{f}_xf_x$, then we have $g_x(x)=0$, $g_x\geq 0$, but $\varphi(g_x)=\varphi(f_x)\varphi(\overline{f}_x)=0$, then there is an open set $O_x$ such that $x\in O_x$, and $g_x(y)>0$ for all $y\in O_x$. Now by compactness, there is $x_1, ..., x_n$ such that $X=\bigcup_{j=1}^nO_{x_j}$, let $g=g_{x_1}+... g_{x_n}$, then we have $g(y)>0$ for all $y\in X$, and $\varphi(y)=0$. Note that $g$ is a continuous function, and $g$ is invertable, and also $re(\frac{1}{g})\in C(X)$, but we also have
    \begin{equation*}
        \varphi \left(g\cdot\frac{1}{g}\right)=1
    \end{equation*}
    Hence we've reached a contradiction.
    Then there exists $x_0\in X$ such that if $\varphi(f)=0$, this means $f(x_0)=0$. For any $f$, consider $f-\varphi(f)\cdot 1$, apply $\varphi$, we have
    \begin{equation*}
        \varphi(f-\varphi(f)\cdot 1)=0, \text{ this implies there exists } x_0, \text{ such that } (f-\varphi(f)1)(x_0)=0
    \end{equation*}
    This implies $f(x_0)=\varphi(f)$ which implies $\varphi(f)=\varphi_{x_0}(f)$.
\end{proof}

For any unital commutative algebra $\mathcal{A}$ and let $\widehat{\mathcal{A}}$ be the set of unital homomorphisms of $\mathcal{A}$ into the field.

For $\mathcal{A}=C(X)$, and $\varphi\in\widehat{\mathcal{A}}$. 
\begin{definition}[spectra of $\mathcal{A}$]
    For any unital commutative algebra $\mathcal{A}$ and let $\widehat{\mathcal{A}}$ be the set of unital homomorphisms of $\mathcal{A}$ into the field, we call the set $\mathcal{A}$ the spectra of $\mathcal{A}$. Sometimes we call $\widehat{\mathcal{A}}$ is called the maximal ideal space of $\mathcal{A}$.
\end{definition}
\begin{remark}
    We have $|\varphi(f)|\leq\|\varphi\|\|f\|_{L^\infty}$, since $\varphi$ is unital, we have $\|\varphi\|=1$.
\end{remark}

Thss is not always true for normed algebra,
Let
\begin{equation*}
    \mathcal{A}:= Poly\subset C([0,1])
\end{equation*}
We define $\varphi(p)=p(2)$, $p$ is a polynomial. This is not continuous, nor is the $\|\varphi\|=1$.


\begin{proposition}
    If $\mathcal{A}$ is a nital commutative Banach algebra, and if $\phi\in\widehat{\mathcal{A}}$, then we have $\|\varphi\|=1$.
\end{proposition}
\begin{proposition}
    Let $\mathcal{A}$ be a unital Banach algebra (not necessarily commutative), then if $a\in\mathcal{A}$, and $\|a\|\leq 1$, then we have
    \begin{equation*}
        1_\mathcal{A}-a \text{ is invertible in } \mathcal{A}
    \end{equation*}
\end{proposition}
\begin{proof}
    For this, we use completeness.
    $\frac{1}{1-a}=?\sum_{n=0}^\infty a^n, a^0=1_\mathcal{A}$
    You could look at the partial sums. $S_m=\sum_{n=0}^ma^n$, you want to show that $\{S_m\}$ is a Cauchy sequence, and use completeness of Banach algebras. $\lim_{m\to\infty}S_m=\frac{1}{1-a}$.
    
    To rove this is a cauchy sequence:
    \begin{equation*}
        \|S_n-S_m\|=\|\sum_{j=m+1}^na^j\|\leq\sum_{m+1}^n\|a^j\|\leq\sum_{m+1}^n\|a\|^j
    \end{equation*}
    And the fact that $\|a\|\leq 1$, we have the sum bounded by $\epsilon$, hence $\{S_n\}$ is a Cauchy sequence. Let $b=\sum_{n=0}^\infty a^n$, we want to show that $b(1-a)=1$.
    \begin{equation*}
        b(1-a)=\lim_{n\to\infty}{S_n}(1-a)=\lim_{n\to\infty}\left(\sum_{n=0}^\infty a^n\right)(1-a)=\lim_{n\to\infty}(1-a^{n+1})=0
    \end{equation*}
    The last inequality follows from $\|a^{n+1}\|\leq\|a\|^{n+1}\to 0$.
\end{proof}

