\chapter{Lecture 1}

here we go.

\section*{Course overview}
We will be discussing the nonlinear Schrodinger quations, which is a subcategory of nonlinear pde's, nonlinear dispersive equations, and infinite speed of propogation, 

Let's start with the linear Schrondinger equation.

\begin{equation*}
    i\partial_tu+\Delta u=0 \text{ in } \R\times\R^n, u(t=0)=u_0
\end{equation*}
The fundamental solution to a Schrondinger equation, is the $K(t,x)$ is such that $u_0=\delta_0$.

Instead, one could look at other intial data, for exmaple, $\widehat{u}_0=\delta_{\xi_0}$, or $u_0=e^{ix\xi_0}$.

\begin{remark}
    If you localize the initial data in the physical space, then the fourier transform is constant and therefore cannot be localized in the Fourier space. The reverse is also true if you try to localize in the Foureir space.
\end{remark}

If we have
\begin{equation*}
    u_0=e^{-\frac{(x-x_0)^2}{2}}e^{i(x-x_0)\cdot\xi_0}
\end{equation*}
For this type of initial data, we call it the coherent state, localized at $(x_0, \xi_0)$

In non-coherent state, the solution spreads out immediately; in the coherent state, the solution remains nicely behaved and coherent for a period of time, then it spreads out evenetually.

\begin{remark}
    This is the idea of group velocity, waves with frequence $\xi_0$ move with velocity $2\xi_0$. This $2\xi_0$ is called the group velocity. 
\end{remark}

Dispersive equation: waves with different frequencies travel in different directions.


\section{Nonlinear}
We will start with the nonlinear boys now.
\begin{equation*}
    i\partial_tu+\Delta u=\lambda u\cdot |u|^p
\end{equation*}
We will ask the following standard pde questions.
\begin{enumerate}
    \item existence
    \item uniqueness
    \item continuous dependent
    \item global in time behavior, i.e. linear vs nonlinear effects
\end{enumerate}
\begin{remark}
    If one just observes the RHS, then there is linear and nonlinear contributions, and one probalby would expect that one dominates over the other over time.
\end{remark}

\textbf{linear}: scattering. nonlinear solution looks like the linear solution

\textbf{nonlinear}: solitons (solutions that remain concentrated for a very long time, such as a bump function), blow-ups.

We will comment on the dispersive aspect of the Schrondinger equation before the nonlinear aspect.


\section{Dispersion}
Here are ways to measure dispersion. Given nicely behaved initial data, $u(t=0)=u_0\in H^s$.
\begin{enumerate}
    \item  dispersive estimates $\|u\|_{L^\infty}\leq t^{O(1)}\|u_0\|_{L^1}$
    \item Strichartz estimates $\|u\|_{L_t^pL_x^q}\leq \|u_0\|_{L^2}$
    \item Lateral Strichartz esiamtes, exchanging the role of $t, x$.
    \item Improved function spaces (Bourgain spaces, $U^p$, $V^p$)
    \item Local energy decay. If you have a dispersive solution, instead of measuring the solution everywhere, say, you measure it in the vertical cylinder.
\end{enumerate}

\textbf{Back to NLS.}
\begin{equation*}
    i\partial_t u+\Delta u=\lambda u|u|^p
\end{equation*}

We will talk about the following:
\begin{enumerate}
    \item local well-posedness
    \item global well-posedness for small initial data
    \item large initial data problem 
    \item energy critical problem $\int|\nabla u|^2$ and the mass critical problem $\int|u|^2$
\end{enumerate}
\begin{remark}
    The exponenet $p$ that we put on the RHS plays an important role int he above questions.
\end{remark}
Some topics in the foreseeable future: Littlewood-Paley theory, Bessel's problem, etc

\textbf{References}: Tao's on nonlinear and dispersive pde.

Now we will talk about Schrondinger maps
\begin{equation*}
    u: \R\times \R^n\to (M, g)
\end{equation*}
Sasy we have $u_t=i\Delta u$, then $u_t\in TM$, where $T$ stands for tangent, as we have rotated $\Delta u$ 90 degrees hence should live in the tangent of the manifold.
\begin{equation*}
    u_t=P\Delta u, P \text{ projection on } TM
\end{equation*}
The RHS $P\Delta u$ is called the heat flow. Let $M$ be a kahlan manifold.

Spherical case, $(M,g)=\mathbb{S}^2$. One can identify $\mathbb{S}^2$ as the comlex plane and compactified.
Hence if we would like an object that is perpendicular to both $u$ and $\Delta u$, and rotate by 90 degrees, then we look at the following equation
\begin{equation*}
    u_t=u\times \Delta u, u(t=0)=u_0
\end{equation*}


Then we come to the next section of the class, Quasilinear Schrondinger equations.
\begin{equation*}
    iu_t+g^{jk}(u)\partial_j\partial_k(u)=N(u, \nabla u), u(t=0)=u_0
\end{equation*}
Suppose $g^{jk}$ is a positive definite matrix, and the $N$ stands for nonlinear We will look at the local solvability. 

If we start with a simple guess, $N=\partial_j u$, and this becomes a ill-posed linear problem due to exponential growth (by taking the Fourier transform). Then we can probably repalce $N=(\nabla u)^2, N=(\nabla)^3$.

Another difficulty is how waves propogate, and ``trapping'' refers to when waves are localized eternally and do not propogate (sit in the vertical cylinder for example). This leads to the discussion of local well-posed theory.

For the \textbf{last part of the course}, we wil look at global solutions for quasilinear Schrondinger equations for small initial data, if $n\geq 3$, then somehow you can use the dispersive estimates mentioned above, via Strichartz. In higher dimension, the decay is faster, than the estimate is stronger, and the linear component plays more role. In low dimension, the nonlinear interactiosn are more prominennt. 

In $n=1$, there exists a following conjecture.
\begin{proposition}[Conjecture]
    If one has $1-d$ dispersive problem, that is cubic defocusing, then there exists a global solution for small data $u_0$.
\end{proposition}
In the case of QNLS, there is a proved theorem as above in 2023.



\section{Lecture 2}

We will now interpret the three quantities introduced above, mass, momentum and energy.

\textbf{First interpretation}
The Hamiltonian interpretation,

denote $H(u)=E(u)$, and $w(u,v)$ antisymmetric in $L^2$, and 
\begin{equation*}
    w(u,v)=\int Im(u\overline{v}), J=i
\end{equation*}
And $\partial_tu=JDH=-id\Delta u$, where $D$ is the differential form.

Given two Hamiltonians, $\{H_1, H_2\}=0$, can ask if they commute. This is to ask whether $H_1, H_2$ flows commute.

\begin{theorem}[Noether]
    Each sympletic symmetry of one Hamiltonian flow is generated by a commuting Hamiltonian.
\end{theorem}
\begin{remark}
    Sympletic refers to the solution preserving the sympletic form.
\end{remark}

$E$ generate the linear Schrodinger equation.

If we look at
\begin{equation*}
    \frac{\delta P_j}{\delta u}-i\partial_j u, \partial)t u-i\cdot i\partial_j u=-\partial_j u
\end{equation*}
This gives
\begin{equation*}
    \partial_t u+\partial u=0
\end{equation*}

This generates translations.

If we look at mass $M$, we have
\begin{equation*}
    \frac{\partial M}{\partial u}=2u, \partial_\theta u=i2u
\end{equation*}

This generates phase rotations.

We note that although mass is a conserved quantity, the mass is moving around. Hence, we associate a flux to it, i.e. a mass density. We define the mass density as follows
\begin{equation*}
    m(u)=|u|^2
\end{equation*}
And we take the time derivative
\begin{equation*}
    \partial_t m=\partial_jf_j
\end{equation*}
where $f_j$ is the mass transfer in the $j$-th direction.

\begin{equation*}
    \partial_tm=2Re(\partial_t u\cdot\overline{u})=2 Re(i\Delta u\cdot\overline{u})
\end{equation*}
Then by integration by parts, we have the above equal to
\begin{equation*}
    2Re(i\partial_j(\partial_j u\cdot\overline{u})-i\partial_ju\cdot\partial_j\overline{u})=\partial_j[2Im(\partial_ju\cdot\overline{u})]=-\partial_jp_j
\end{equation*}


We have shown that
\begin{equation*}
    \partial_jm(u)+\partial_jp_j=0
\end{equation*}
We could do similar computations for momentum.
\begin{equation*}
    \partial_tp_j+\partial_ke_{jk}=0
\end{equation*}
Where for the matrix $e_{jk}$, the trace of the matrix is equal to $e$, denoted as the energy density.
The above two equations give rise to the "Energy-momentum tensor is divergence free."?

$\begin{bmatrix}
    m & P \\
    P & e
\end{bmatrix}$
The divergence of the above matrix is equal to 0.

Solutions for the (LS).
We go back to the fundamental solution. For $u+0=\delta_0$. We have
\begin{equation*}
    \widehat{K}=e^{it\xi^2}\widehat{u}_0=e^{it\xi^2}
\end{equation*}
We thus have
\begin{equation*}
    K(t,x)=\frac{1}{(2\pi it)^{n/2}}e^{-ix^2/4t}
\end{equation*}

The dirac is Galilean invariant, and so is the fundamental solution, and $|K(t,x)|$ has to say constant due to Galilean invariance. Hence we have
\begin{equation*}
    |K(t,x)|=c_n\cdot t^{-n/2}
\end{equation*}

And we also have infinite speed of propogation, wave packets travel in all directions with the same speed, and do no discriminate different speeds.

Connection between propogation speed and frequency.
For
\begin{equation*}
    \partial_t\widehat{u}=it\xi^2\cdot u
\end{equation*}

Suppose $u$ only has frequencies close to $\xi_0$. Let's approximate $\xi$, Given
\begin{equation*}
    \xi^2=\xi_0^2+2\xi_0(\xi-\xi_0)
\end{equation*}

Approximate equation
\begin{equation*}
    \partial_t\widehat{u}=i[\xi_0^2+2\xi_0(\xi-\xi_0)]\widehat{u}=(2i\xi_0\cdot\xi-i\xi_0^2)\widehat{u}
\end{equation*}
Coming back to the physical space, we have
\begin{equation*}
    \partial_t{u}=2\xi_0\cdot\partial_xu-i\xi_0^2u
\end{equation*}
The first partial refers to the transport, and the second refers to the phase rotation.

This gives that $u(t,x)=u_0(x,x+2t\xi_0)e^{-it\xi_0^2}$. This gives the conclusion that waves with frequency $\xi_0$ now move with velocity $2\xi_0$.

(We may have a sign error, but imagine we have $\tau+\xi_0^2$), and the velocity $2\xi_0$ is called the roup velocity. If we denote $\tau+\xi^2$ as $\tau+\alpha(\xi)$ , then the group velocity is $\partial_\xi\alpha(\xi)$.

If the velocity of waves depends on frequency, we thus call this dispersive.

If I choose $u_0=e^{ix\xi_0}$, then we get
\begin{equation*}
    u(t)=e^{i(x_2t\xi_0)}\cdot e^{-it\xi_0^2}
\end{equation*}
The first part comes from the transport and the second part comes from the phase shift.

We have $\widehat{u}_0=\delta_{\xi_0}$. 

If we have $u_0=e^{-x^2/2}$, and $\widehat{u}_0=e^{-\xi^2/2}$, and $(x_0, \xi_0)=(0,0)$, and $(\delta x, \delta \xi)=(1,1)$.

Then $\widehat{u}(t,\xi)=e^{-it\xi^2}e^{-\xi^2/2}$. 

This gives
\begin{equation*}
    u(t,x)=\frac{1}{((1/2_it)2\pi)^{n/2}}e^{-x^2/(2-4it)}
\end{equation*}
Note that if $t\lesssim 1$, then it behaves nicely like a Gaussian, and if otherwise, we have waves spread out because the $4it$ term dominates.

Before a time threshold, we have the coherent state, where everything stays like a Gaussian, but becomes dispersive after some time.

Given Galilean invariance and translation invariance, we can move to $\xi_0$ and then to $x_0$. Hence now we have
\begin{equation*}
    u_0=e^{-(x-x_0)^2/2}e^{i(x-x_0)\xi_0^2}
\end{equation*}

These translations do not commute, however, it only varies our solution by a constnat factor, say $e^{i\xi_0^2}$ or something. The form of above $u_0$ is called the coherent state.

And we call the coherent state solutions, moving with velocity $2\xi_0$ as wave packets. And still $\delta x=1, \delta\xi=1$. And the time of coherent is 1, $\delta t=1$.

What if we want to change the scale, i.e. the sclaing symmetry. $(t,x)\mapsto (\lambda^2 t, \lambda x)$.

\begin{equation*}
    \delta t=T, \delta x=\sqrt{T}, \delta\xi=\frac{1}{\sqrt{T}}
\end{equation*}

By this scaling relation, We can adjust the time of the coherent state.

We can also think of LS solutions as superpositions of wave packets.

\section{Lecture 3}
We recall what we did last time.
\begin{equation*}
    (i\partial_t+\Delta)u=0, u(0)=u_0
\end{equation*}
And we have
\begin{equation*}
    u_0(x)=e^{-(x-x_0)^2/2}e^{ix_0(x-x_0)}
\end{equation*}
This refers to the coherent state, and it suffices to study $x_0=\xi_0=0$, and use translation invariance.


And note that we have $(x_0, \xi_0)$ as the center and the scales are $\delta x=1, \delta\xi=1$. 

We note this is not the only scale. We could instead have $\delta x=\sqrt{T}, \delta\xi=\frac{1}{\sqrt{T}}$, and for scale=1, we have coherent $T=1$. And for the other scale, we have the coherent time $T$ as $T$.

Now we ask the following questions:
Question: can we think of arbitrary solutions as superpositions of wave packets?

We want $u_0$= linear combination of coherent states. In other words, we now replace our typical $e^{-x^2/2}$ with any Schwartz function $\varphi$, and we have
\begin{equation*}
    u_0(x)=\varphi(x-x_0)e^{i\xi_0(x-x_0)}
\end{equation*}
Moreover, another justification to use arbitrary schwartz function is that if we are trying to solve
\begin{equation*}
    i\partial_tu-A(D)u=0, a\mapsto a(\xi)
\end{equation*}
Then there is no reason to use $u_0$ as the Gausssian $e^{-x^2/2}$ because the Gaussian does not stay Gaussian as it evolves.

We could use partition of unity. Let $\mathbb{Z}\subset\mathbb{R}^n$, we have
\begin{equation*}
    1=\sum_{j\in\mathbb{Z}^n}\chi_j(x)
\end{equation*}
And $\chi_j(x)=\chi(x-x_j)\in\mathcal{S}$. Now we have each $\chi_j$ contained in a unit cube.

And we have
\begin{equation*}
    u_0=\sum\chi_j(x)u_0=\sum_{k\in\mathbb{Z}^n}\sum_{j\in\mathbb{Z}^n}\chi_k(D)\chi_j(x)\cdot u_0
\end{equation*}
The above is called the spatial unit scale decomposition. However, this decomposition is not smooth compared to our initial form of the data.

Now we ask the question, how about a smooth wave packet decomposition.
\begin{equation*}
    u=\int f(x_0, \xi_0)u_{x_0, \xi_0}(x)dx_0d\xi_0
\end{equation*}
\begin{remark}
    The representation is not unique, and it one wishes to make this unique, they would have to have some sort of restriction on $f(x_0, \xi_0)$
\end{remark}

This is the Bargmann trnsform, or the Segal transform. If one includes the scaling, this is called FBi transform.

\begin{definition}
    Let $T$ be defined as follows: (using Gaussians)
    \begin{equation*}
        f(x_0, \xi_0)=Tu(x_0, \xi_0)=\int e^{-(x-x_0)^2/2}e^{-i\xi_0(x-x_0)}u(x)dx
    \end{equation*}
    Note we cannot hope this to be surjective, hence we have twice the amount of variables of $x_0, \xi_0$. Note we start with $x$, and end with a function in two variables.
\end{definition}

If we differentiate with respect to $\xi_0$, we get a $i(x-x_0)$ term, and if we differentiate with respect to $x_0$, we get a $(x-x_0)$ term, as well as $i \xi_0$ term, hence we have the following operator that kills the phase.
\begin{equation*}
    \left[\partial_{\xi_0}-i(\partial_{x_0}-\xi_0)\right]Tu=0
\end{equation*}

\begin{proposition}
    Such $T$ defined above, as the Bargmann transform, is an $L^2$ isometry.
    \begin{equation*}
        T*\circ T=I
    \end{equation*}
\end{proposition}


We define a slightly different transform:
\begin{equation*}
    \tilde{T}u(z)=\int e^{-1/2(x-z)^2}u(x)dx, z=x_0-i\xi_0
\end{equation*}
And now we have
\begin{equation*}
    \tilde{T}: L^2\to L^2(e^{-\xi_0^2})
\end{equation*}


\begin{definition}
    The FBi transform is simply a recaled version of the Bargmann transform.
    \begin{equation*}
        T_\lambda u(x_0, \xi_0)=\int e^{-(x-x_0)^2/2\lambda}e^{-i\xi_0(x-x_0)}u(x)dx
    \end{equation*}
\end{definition}
Now we have $\Delta x=\sqrt{\lambda}$, and $\xi=1/\sqrt{\lambda}$.

We have
\begin{equation*}
    u_0=\sum_{x_0, \xi_0\in\mathbb{Z}^n}c_{x_0, \xi_0}u_0^{x_0, \xi_0}
\end{equation*}
Then we have
\begin{equation*}
    u=\sum c_{x_0, \xi_0}e^{-itD^2}u_0(x_0, \xi_0)
\end{equation*}
The above is the solution to the linear Schrondinger. This is useful up to time 1, and it is viewed as a superposition of wave packets.

We shall approximate wave packets, we have $u_0$ localized at $(x_0, \xi_0)$. We approximate the solution as follows:
\begin{equation*}
    u(x,t)\sim u_0(x-2t\xi_0)e^{it\xi_0^2}
\end{equation*}
If we start with $e^{i(x-x_0)\xi_0}$, then roughtly it is $e^{i(x-2t\xi_0-x_0)}\xi_0$, where $\xi\sim\xi_0$, and $\tau\sim-\xi_0^2$. 

Then $u$ is a good approximate solution, you can verify this by 
\begin{equation*}
    (i\partial_t+\Delta)u\sim O(1)
\end{equation*}
However, this error adds up and is acceptable if $t<< 1$. Especially if you have nonhomogenous equation, the error adds up as time progresses.

We have
\begin{equation*}
    u(t,x)=\sum_{x_0,\xi_0}c_{x_0, \xi_0}u_0(x-2t\xi_0)e^{it\xi_0^2}
\end{equation*}
And this is a good approxiamte solution up to time 1.

\begin{remark}
    We note that the composition here is almost orthogonal, hence we have different frequencies, just like we had agove when we had $u=\sum c_{x_0,\xi_0}e^{-itD^2}u_0(x_0, \xi_0)$
\end{remark}

In the constant coefficient case, you start with $(x_0, \xi_0)$, at $t=0$, you end up at $(x_0+2\xi_0, \xi_0)$
But in variable coefficients, you have
\begin{equation*}
    (x_0, \xi_0)\to (x_t, \xi_t)
\end{equation*}
We no longer move in the linear fashion.

We now explore the case where we don't assume infinitely many derivatives. 

Let's consider wave packets with less localization. Simply consider the case at $(0,0)$ and use translation invariance and Galilean symmetry.

Take $u_0\in L^2$, what does it mean for this to be localized at (0,0)?

One proposition could be
\begin{equation*}
    x\cdot u_0\in L^2
\end{equation*}
This means as long as you move away from (0,0), $u_0$ decays. And we would also like to have decay in frequence, hence
\begin{equation*}
    \partial_xu_0(x,\xi)\in L^2
\end{equation*}
The above implies decay in $\xi$. Together they imply the solution $u$ is localizated at $(0,0)$ up to time $O(1)$.

If you wish it to localize at $(x_0-2t\xi_0, \xi_0)$, then we can have
\begin{equation*}
    (x-x_0-2t\xi_0)u\in L^2, [D_x-\xi_0]u_0\in L^2
\end{equation*}

By energy estimates, we have if $u$ solves the equation, then $D_xu$ also solves the equation, we have
\begin{equation*}
    \|D_xu\|_{L^2}=\|D_xu(0)\|_{L^2}
\end{equation*}
So it remains to consider $xu$, and how it interacts with the equation. We have
\begin{equation*}
    (i\partial_t+\Delta)x_ju=x_j(i\partial_t+\Delta)u+2\partial_ju
\end{equation*}
And the first term is 0, hence we have
\begin{equation*}
    \frac{d}{dt}\|xu\|_{L^2}^2=Re\int 2\overline{u}\partial_j udx=O(1)
\end{equation*}
Then we have $\overline{u}\in O_{L^2}(1), \partial_j u\in O_{l^2}(1)$, hence the entire term is of $O(1)$ in $L^2$.

Recall the fundamental solution of linear Schrondinger equation.
\begin{equation*}
    K(t,x)=\frac{1}{(4\pi it)^{n/2}}e^{ix^2/4t}, |K|\lesssim t^{-n/2}
\end{equation*}
Hence we have $u(t)=K(t)\ast u_0$. 
And we have the dispersive estimate for linear Schrondinger
\begin{equation*}
    \|u(t)\|_{L^\infty}\leq\|K(t)\|_{L^\infty}\|u_0\|_{L^1}\lesssim t^{-n/2}\|u_0\|_{L^1}
\end{equation*}

Dispersive estimates via stationary phase.

Let's generalize to variable coefficents.
\begin{equation*}
    (i\partial_t+A(D)\Delta)u=0
\end{equation*}
And our solution is of the form
\begin{equation*}
    u(t)=e^{itA(D)}u(0)
\end{equation*}
and
\begin{equation*}
    K(t)=\int_{\R^n}e^{ix\xi}e^{-ita(\xi)}d\xi
\end{equation*}

We have the oscillatory integral
\begin{equation*}
    I_\lambda=\int e^{i\lambda \varphi(\xi)}a(\xi)d\xi
\end{equation*}
Where we assume $a(\xi)$ having compact support.


And the value of the integral depends on the stationary points, defined by $D\varphi=0$.

If there are no stationary points, then we get
\begin{equation*}
    |I_\lambda|\leq \lambda^{-N}
\end{equation*}

Replace $\varphi$ with a quadratic expansion, and ``replace'' with a Gaussian. If we have nondegenerate points, $D\varphi\neq 0$. We have
\begin{equation*}
    |I_\lambda|\leq\lambda^{-n/2}
\end{equation*}
It's like putting $\varphi$ in $n-1$ dimension and operate with separation of variables.

We now examine our solution to the Schrondinger equation, and find the critical points here. We differentiate with respect to $x_j$
\begin{equation*}
    x_j+t\partial_{\xi_j}a(\xi)=0
\end{equation*}
We have
\begin{equation*}
    v\sim x/t=a_\xi
\end{equation*}
where $a_\xi$ is our previous group velocity.

The nondegenerate points are characterized as nonvanishing Hessian, which is $\sim D^2a$.
\begin{definition}
    The nondegenerate points are defined by the Hessian $\sim D^2a$, being a nondegenerate matrix.
\end{definition}
In LS, we have
\begin{equation*}
    a=\xi^2, D^2a=2I
\end{equation*}

Now we introduce a third way of viewing dispersive estimates, which is via \textbf{wave packets}.

We first note that the dispersive estimate
\begin{equation*}
    \|u\|_{L^\infty}\lesssim t^{-n/2}\|u_0\|_{L^1}
\end{equation*}
is scale invariant.  Hence it suffices to focus at $t=1$.

Let's take
\begin{equation*}
    u_0=\delta_0=\sum_{x_0,\xi_0\in\mathbb{Z}^n}c_{x_0, \xi_0}\varphi_{x_0, \xi_0}
\end{equation*}
we have
\begin{equation*}
    u_0=\sum\chi_j(x)u_0=u_0
\end{equation*}
And we want to localize frequency
\begin{equation*}
    \widehat{u_0}=\widehat{\delta_0}=1=\sum_{k\in\mathbb{Z}^n}\chi_k(\xi)
\end{equation*}
We have the $\|\chi_k\|_{L^2}=1$, and this says the Fourier coefficents are of $O(1)$.

Then
\begin{equation*}
    u=\sum_{x_0=0,\xi_0\in\mathbb{Z}^n}c u_{x_0, \xi_0}
\end{equation*}
At time $t=1$, we get one of the wave packet each, hence we have
\begin{equation*}
    |K(t=1)|\leq \sup_{\xi_0}|u_{x_0,\xi_0}|=1
\end{equation*}
\begin{remark}
    This no longe words for $t<<1$, hence there exists overlappings now. But to fix this, we rescale $\delta x=\sqrt{T}$, to get smaller and thinner tubes, nonoverlapping at time $T$.
\end{remark}

Now we ask the question, what is the good way to measure dispersive decay for $u_0\in L^2$.

\textbf{A1}: there is no uniform decay bound of the form
\begin{equation*}
    \|u(t)\|_{Sobolev}\leq C(t)\|u_0\|_{L^2}, \lim_{t\to\infty}C(t)=0
\end{equation*}

This is because $\|u(t)\|_{L^2}=\|u_0\|_{L^2}$, and taking $t$ infinitely large, $C(t)$ tends to 0, and we would get 
\begin{equation*}
    \|u\|_{sobolev}\leq 0, t\to\infty
\end{equation*}

Next time, we will talk about Strichartaz estimates, not in a uniform way, but in an average sense of $\|u\|_{L_t^pL_x^2}$. 


\section{Lecture 4}
We will talk about Strichartz estimates this time. Suppose $u$ is a solution to 
\begin{equation*}
    iu_t+\Delta u=0, u(0)=u_0
\end{equation*}
We ask if there exists a following bound
\begin{equation*}
    \|u\|_{L_{t,x}^p}\lesssim \|u_0\|_{L_x^2}
\end{equation*}
We cannot expect to use the same exponents for $t,x$ hence we will attempt to put $L_t^pL_x^q$ instead.

Note we can also interchange the role of $t,x$, which are probably called maximal inequalities, but for now, we stick to this order for $t,x$. Sobolev embeddings in $\R^n$ also relates $L^p$ norms with $L^2$, such as
\begin{equation*}
    \|u\|_{L^p}\lesssim \|u\|_{\dot{H}^s}=\||D|^su\|_{L^2}
\end{equation*}
except having derivatives on the RHS. Hence in general, we look for inequalities of the form
\begin{equation*}
    \|u\|_{L_t^pL_x^q}\lesssim \||D|^su_0\|_{L^2}
\end{equation*}
Before trying to figure out the indices $p,q,s$, we first note the symmetries of the Schrodinger equations. We use the scaling symmetry first. In other words, we want both spaces invariant under the transformation
\begin{equation*}
    u(t,x)\mapsto u(\lambda^2t, \lambda x)
\end{equation*}
We end up with the following scaling relation.
\begin{equation*}
    \frac{2}{p}+\frac{n}{q}=\frac{n}{2}-s
\end{equation*}
The other piece of information can be derived from wave packets and the Galilean symmetry. What we saw last time is that we can produce wave packets $u_p\approx 1$ of size 1 in a rectangle $(T^{1/2})^\times T$, where $T^{1/2}$ is the spatial $\delta x$, and $\delta t\approx T$. The dual scale is $\delta\xi\approx T^{-1/2}$ due to the uncertainty principle. We can put $\delta\xi$ to localize at anywhere in the Fourier space, so if we restrict to $|\xi|\approx 1$, then we would want $\delta\xi\ll 1$, hence $T\gg 1$. This implies the following relationship:
\begin{equation*}
    T^{\frac{1}{p}}T^{\frac{n}{2q}}\lesssim T^\frac{n}{4}
\end{equation*}
for $T\gg 1$. Hence in fact we have
\begin{equation*}
    \frac{2}{p}+\frac{n}{q}\leq\frac{n}{2}
\end{equation*}
If you were to compare these two, then $s\geq 0$. We thus name them:
\begin{enumerate}
    \item sharp Strichartz: $s=0$
    \item non-sharp Strichartz: $s>0$
\end{enumerate}
From the sharp to non-sharp, we will use Sobolev embeddings. Though it seems like the derivation with $s$ included is redundant, if you take wave equations or the KDV equations instead, then there exists a number of derivatives $s$ there for these kinds of Strichartz estimates.

\subsection{Strichartz estimates, restriction theorems in Harmonic analysis}
We will now focus on $\widehat{u}=\delta_{T=-|\xi|^2}\widehat{u_0}(\xi)$, which are $L^2$ measures on the paraboloids.
\begin{equation*}
    \widehat{u_0}\mapsto\mathcal{F}^{-1}\delta_{\tau=-|\xi|^2}\widehat{u_0}: L^2\to L_t^pL_x^q
\end{equation*}
The adjoint operator is $f\mapsto (\mathcal{F}_{t,x}f)\vert_{\tau=-|\xi|^2}: L^{p'}L^{q'}\to L^2$, trace of this Fourier transform on the paraboloids, we want it to be from $L^{p'}L^{q'}\to L^2$.

Strichartz estiamtes $L^2\to L^pL^q$, the second one is called the restriction theorem. In PDE's, we are looking for $L^2$ and harmonic analysts want to change $L^2$ to other exponents and look for the range of it, and don't care about different exponents $p', q'$, hence choosing them to be equal. 

Also, in harmonic analysis, one may not only consider the case for paraboloids.
\begin{enumerate}
    \item sphere: Stein-Thomas theorem, 70s
    \item cone: Strichartz, 80s
    \item paraboloids, 80s
\end{enumerate}
\begin{remark}
    All the above shapes considered have nonvanishing curavture, both sphere and hyperboloids have maximal number of nonvanishing curvature while the cone has one less.
\end{remark}

\subsection{Visualization, $p\geq 2$}
Before we prove anything, we make one more observation. We look at the scaling relationship:
\begin{equation*}
    \frac{2}{p}+\frac{n}{q}=\frac{n}{2}
\end{equation*}
When $n=1$, we draw a graph with $1/p-1/q$ coordinates. The $L^\infty L^2$ endpoints is invariant regardless of the dimension, due to the $L^2$ norm being preserved. When $n\geq 3$, one of the endpoints is $\frac{4}{n}$, which might be less than 1.

What if we try to construct various wave packets $u_j$ of size 1 inductively (where each is far away from the previous ones both in space and frequency)? If we measure $u=\sum c_ju_j$, then 
\begin{equation*}
    \|u\|_{L^2}^2=\sum_jc_j^2
\end{equation*}
However, we also have
\begin{equation*}
    \|u\|_{L^pL^q}^p=\sum c_j^pl^2
\end{equation*}
which controls $l^p$, hence we would want $p\geq 2$. 

For $n=1$, we have the full range. For $n=2$, we have one forbidden endpoint; for $n=3$, we only care about the RHS of the shadow region, and we also have endpoint estimates.

\subsection{$T^*T$-method}
Last time, we proved the following dispersive estimates:
\begin{equation*}
    \|e^{itD^2}u_0\|_{L^\infty}\lesssim t^{-n/2}\|u_0\|_{L^1}
\end{equation*}
We want $u_0\to e^{itD^2}u_0$ is $L^2\to L^pL^q$. Combining with the trivial $L^2$ bound (isometry), we interpolate them to obtain the following
\begin{equation*}
    \|e^{itD^2}u_0\|_{L^p}\lesssim t^{-\frac{n}{2}(\frac{1}{p'}-\frac{1}{p})}\|u_0\|_{L^{p'}}
\end{equation*}
note that the exponent of $t$ is determined by scaling. Note this holds for $(L^1)'=L^\infty$, and $(L^2)'=L^2$.

Let us denote the operator $T: u_0\to e^{itD^2}u_0$. (The LHS has duality in $n$-dim, the RHS has duality in $n+1$-dim). Having this operator from $L^2\to L^pL^q$ is the same as having the dual operator:
\begin{equation*}
    T^*: f\mapsto \int e^{-itD^2}f(t)dt, T^*: L^{p'}L^{q'}\to L^2
\end{equation*}
A fundamental result in functional analysis is that $T$ is bounded if and only if $T^*$ is bounded.

\begin{definition}[$TT^*$-method]
    Given $T: L^2\to L^pL^q$, we consider the following operator:
    \begin{equation*}
        TT^*: L^{p'}L^{q'}\to L^pL^q
    \end{equation*}
    We have $T$ is bounded if and only if $T^*$ is bounded, if and only if $TT^*$ is bounded.
    \begin{equation*}
        \langle TT^*(f), g\rangle=\langle T^*(f), T^*(g)\rangle
    \end{equation*}
    where $g\in L^{p'}L^{q'}$, and taking $f=g$, we have
    \begin{equation*}
        \|T^*(f)\|_{L^2}^2\lesssim \|f\|_{L^pL^q}^2\|TT^*\|
    \end{equation*}
    This is called the $TT^*$ argument.
\end{definition}
\begin{remark}
    The essence of this method is that one of the spaces is $L^2$.
\end{remark}

We write
\begin{equation*}
    TT^*(f)(t)=e^{itD^2}T^*f=\int_\R e^{i(t-s)D^2}f(s)ds
\end{equation*}
where $t,s$ are arbitrary instead of the actual fundamental solution for the Schrodinger equation. So 
\begin{equation*}
    \|TT^*(f)\|_{L^q}\lesssim\int_\R|t-s|^{-\frac{n}{2}(\frac{1}{q'}-\frac{1}{q})}\|f(s)\|_{L^{q'}}ds
\end{equation*}
By Young's inequality, we have the exponents
\begin{equation*}
    \frac{n}{2}\left(\frac{1}{q'}-\frac{1}{q} \right)\in (0,1)
\end{equation*}
hence $2<p<\infty$. 

\begin{remark}
    The convolution with $1/|t|: L^2\to L^2$ is not true for Young's inequality, hence in Hilbert transform, we want to use p.v. instead of absolute value.
\end{remark}

So far, we have looked at only homogeneous euqations. For inhomogeneous ones, i.e. $iu_t+\Delta u=f$, we can write the solution into two components,
\begin{equation*}
    u(t)=e^{itD^2}u_0+\int_0^te^{i(t-s)D^2}f(s)ds
\end{equation*}
which is the standard Duhamel's formula. For the first component, we know the mapping property from $L^2$. For the second one, if we want $u\in L_t^\infty L_x^2$, it is enough to fix $t$, then we look at the map
\begin{equation*}
    f\mapsto \int_0^te^{i(t-s)D^2}f(s)ds
\end{equation*}
We want to compare this with the operator $T^*$. In fact, the time range 0 to $t$ does nothing, so this maps from $L^{p'}L^{q'}\to L^2$. You might conjecture the correct form for the estimates are
\begin{equation*}
    \|u\|_s\leq\|u_0\|_{L^2}+\|f\|_{s'}
\end{equation*}
where $s$ is our favorite Strichartz norm. We have proved the case for $f=0$. Also, when $f\neq 0$, we also proved for $s=L^\infty L^2$. However, the nontrivial Strichartz norms can also be proved. In fact, we have more general forms:
\begin{equation*}
    \|u\|_{L^pL^q}\lesssim \|f\|_{L^{p_1'}L^{q_1'}}
\end{equation*}

For forward problems,
\begin{equation*}
    u(t)=\int_{-\infty}^t e^{i(t-s)D^2}f(s)ds
\end{equation*}
is a convolutional operator and the kernel for this is 
\begin{equation*}
    1_{t\geq s}e^{i(t-s)D^2}
\end{equation*}
where restricting $1_{t\geq s}$ also means you are viewing the forward problem. Note that the difference between this and the kernel for $TT^*$  operator is that the kernel for $TT^*$ is $e^{i(t-s)D^2}$ without restriction.

\subsection{Christ-Kiselev Lemma}
We now state a classical lemma:
\begin{lemma}[Christ-Kiselev]
    Suppose the operators
    \begin{equation*}
        L: f\mapsto \int K(t,s)f(s)ds, L^r: f\mapsto \int_{t\geq s}K(t,s)f(s)ds
    \end{equation*}
    which satisfy $L: L^{p_1}\to L^{p_2}$, then if $p_1<p_2$, then we have
    \begin{equation*}
        L^r: L^{p_1}\to L^{p_2}
    \end{equation*}
\end{lemma}
\begin{proof}
    For $1_{t\geq s}$, and $t,s\in [0,1]$, a rectangle $R$ is easy to manipulate since $1_R=1_{t\in I}\times 1_{s\in J}$. However for $t\geq s$, it is not a rectangle.

    The problem of choosing this: we cannot ensure the same amount of $f$ being split inot different intervals. Instead of making a equipartition of the interval, we split the intervals containing the same amount of $f$. Assume $\|f\|_{L^{p'}}=1$, and $[0,1]_s=I_0\cup I_1$ such that $\|f\|_{I_0}=\|f\|_{I_1}=\frac{1}{2^{p_1}}$. Then we split to $I_0=I_{00}\cup I_{01}$.

    Hence we write
    \begin{equation*}
        I_{t\geq s}=\cup_k\cup_{R\in R_k}I_R\times J_R
    \end{equation*}
    where $k$ tells us which layer we are at, and $R_k$ are rectangles at level $k$. All disjoint, both horizontally and vertically. We want to write $L^r(f)=\sum_k\sum_{R\in R_k}1_{I_R}L1_{J_R}f$, where we want to estimate for each $k$,
    \begin{equation*}
        \sum_k\sum_{R\in R_k}1_{I_R}L1_{J_R}f:=\sum_k L_k^rf
    \end{equation*}
    In each layer, we gain something in size. Our claim is that 
    \begin{equation*}
        \|L_k^r\|\lesssim 2^{1/p_2-1/p_1}k
    \end{equation*}
    then this sums in a good way. We know the size $1_{J_R}f$ and mapping property of $L$. For $1_{I_R}'s$. they are disjoint, so the $L^q$ norms add nicely. By composing these three, we get the desired result.
\end{proof}
\qed



This will not cover the double endpoint case where $p=p'=2$. Once you have bounds $TT^*$, you can consider $T,T^*$, to vary $q, q_1'$ to have two different pair of admissible $(p,q)$ and $(p_1, q_1)$. 

Note it is easy to handle the direction from $1_{t\geq s}e^{i(t-s)D^2}$ to $e^{i(t-s)D^2}$ just by time reversal. We just handle two parts and add them together but this is not the direction that we want.

By next time, this C-K will become obselete in the context of the Schrodinger equation. In $n\geq 3$, we need to discuss the endpoint case.

\subsection{The forbidden endpoint in $n=2$}


\section{Lecture 5}

\section{Lecture 6}
We look at the Schrodinger equation $iu_t+\Delta u=f, u(t=0)=u_0$. Last time, we looked at Strichartz estimates:
\begin{equation*}
    \|u\|_S\leq \|u_0\|_{L^2}+\|f\|_{S'}
\end{equation*}
where $S=\cap_{(p,q)}L_t^pL_x^q$, is the Strichartz norm, where the exponents satisfy the scaling relation, $2/p+n/2=n/2$. 

Note that if $u\in C(L^2)$, then $u\in S$. The first thing we note that the Strichartz estiamtes are not specific to the Schrodinger equation, but rather, we can apply it to the more general setting:
\begin{equation*}
    i\partial_t u+A(D)u=f
\end{equation*}
we need $a(\xi)$ to have dispersive relation, and $\partial^2a$, i.e. the Hessian, nondegenerate.

Back to linear Schrodinger. In $n=1$, if we draw the dispersive relation of the Schrodinger (Figure 1). The idea now is to exchange the role of $t$ and $x$. We get 
\begin{equation*}
    \tau+\xi^2=0\Rightarrow \xi=\pm\sqrt{-\tau}
\end{equation*}
Hence we now obtain two solutions $u_R, u_L$, and we take $u=u_L+u_R$.
\begin{equation*}
    (i\partial_x-\sqrt{-D_\tau})u^R=0, (i\partial_x-\sqrt{-D_\tau})u^L=0
\end{equation*}
Recall the (lateral) Strichartz estimates:
\begin{equation*}
    \||D_x|^Su\|_{L_x^pL_t^q}\leq\|u_0\|_{L^2}
\end{equation*}
Note that for the Schrodinger equation, we do not have any derivatives on the LHS, however, derivatives should arise when we change different $p,q$. 

Recall the curvature relation: (we are still in $n=1$)
\begin{equation*}
    \frac{2}{p}+\frac{n}{q}=\frac{n}{2}
\end{equation*}
Now the scaling relation, time counts as two space dimension, hence
\begin{equation*}
    \frac{1}{p}+\frac{2}{q}-s=\frac{1}{2}
\end{equation*}

If we take $(p,q)=(\infty,2)$, then $s=1/2$. This is one endpoint, and this is a gain. The other endpoint, $(p,q)=(4,\infty)$, we have $s=-1/4$, which is a loss.

\begin{proposition}
    By lateral Strichartz estimates, we have the following:
    \begin{equation*}
        \|D^{1/2}u\|_{L_x^\infty L_t^2}\leq\|u_0\|_{L^2}
    \end{equation*}
    \begin{equation*}
        \|D^{-1/4}u\|_{L_x^4 L_t^\infty}\leq\|u_0\|_{L^2}
    \end{equation*}
\end{proposition}


What happens when $n>1$? We gain have
\begin{equation*}
    \tau+\xi^2=0
\end{equation*}
Choose one distinct direction $\xi_1$, and $x_1$ as the evolutionary variable.
\begin{equation*}
    \tau+\xi_1^2+(\xi')^2=0 \Rightarrow \xi_1=\pm\sqrt{-\tau-(\xi')^2}
\end{equation*}
Note the RHS can vanish now, which creates problems. In other words, previously, $\xi$ or $\xi_1$ could not be 0, since it would require $\tau=0$ as well. Now if we are unlucky, and $\xi_1=0$ for some choice of $\tau, \xi'$, then there are waves that do not travel in the $x_1$ direction. (Figure 4)

In figure 5, we avoid this issue by restricting our solution to a cone, for example. Hence if we only look at solutiosn located in this region, we get
\begin{equation*}
    u\to P_1(D)u
\end{equation*}
we have a solution that is dispersive in the $x_1$ direction. Apply the lateral Strichartz estimates:
\begin{equation*}
    \||D_x|^sP_1u\|_{L_{x_1}^pL_{x',t}^q}\leq\|u_0\|_{L^2}
\end{equation*}
Note that we have the same curvature relation, but for the scaling relation, we have (since time acts as two variable and $x'$ has $n-1$, hence get $n+1$ for the second term)
\begin{equation*}
    \frac{1}{p}+\frac{n+1}{q}-s=\frac{n}{2}
\end{equation*}

\begin{remark}
    We make note that there exists gain and there exists loss, since one can always take $p=q$, which is a middle point. And this is like the Strichartz estimate that we had before, where we have no derivatives.
\end{remark}

\begin{proposition}
    We have the more refined lateral Strichartz estimates where we have gains and losses;
    \begin{equation*}
        \|D_x^+u\|_{L_x^\infty L_t^2}\leq\|u_0\|_{L^2}
    \end{equation*}
    Note that this one has nothing to do with dispersion, due to $L^2$ norm being perserved.
    \begin{equation*}
        \|u\|_{L^pL^p}\leq \|u_0\|_{L^2}
    \end{equation*}
    This one does not see direction of travel, and it only sees curvature.
    \begin{equation*}
        \|D_x^- u\|_{L_x^2L_{x',t}^q}\leq\|u_0\|_{L^2}
    \end{equation*}
    This also depends on the curvature
\end{proposition}
\begin{remark}
    We say it depends on curvature when it does not depend on the angular decomposition like in Figure 5. And thus the middlepoint, the bottom endpoint does not depend on the angular decay.
\end{remark}

Note there is something missing in the Strichartz estimates that need to be compensated for having something else.

Note that $L_x^p L_t^q$ are spaces that are invariant to translations and phase shifts.
\begin{equation*}
    \|u\|_{L^pL^q}=\|e^{ix\xi}u\|_{L^pL^q}
\end{equation*}
However, the phase shift generated by multiplying $e^{ix\xi}$ changes where the solution lies in the Fourier space. In other words, the Strichartz estimates do not see where the solution lies in the Fourier space.

\begin{equation*}
    i\partial_t u+\Delta u=u^2=u\cdot u
\end{equation*}
where the first $u$ localized in $\xi_1$, and second $u$ localized in $\xi_2$. We multiply them together, hence get a convolution in the Fourier space, $(\xi_{11}-\xi_1^2), (\xi_{21}-\xi_2^2)$. Then we would add these to up due to convolution. And note that for paraboloids, which are convex, hence adding two points on the characteristic set would give you a point strictly inside the paraboloid.

Now Bourgain.
\begin{equation*}
    \Delta u=f, \dot{H}^s, |\xi|^s
\end{equation*}
And our characteristic set $\tau+\xi^2=0$, we use $|\tau+\xi^2|^b$, and $|\xi|^s$, where $|\tau+\xi^2|^b$ is the distance from the characteristic set in the verticle direction.

\begin{definition}[Bourgain space]
    We define a norm as follows:
    \begin{equation*}
        \|\widehat{u}\cdot|\xi|^s|\tau+\xi^2|^b\|_{L^2}=\|u\|_{\dot{X}^{S,b}}
    \end{equation*}
\end{definition}
\begin{remark}
    $s$ refers to the intial data regularity, $u_0\in H^s$. and $b$ refers to the Sobolev regularity away from the chraactersitic set.
\end{remark}
Let's now interpret $b$. Fix $|\xi|=1$, and set $s=0$.
\begin{equation*}
    \widehat{u}\cdot |\tau+\xi^2|^n=f, \text{ where } f\in L^2
\end{equation*}
Does this definition make sense?
\begin{equation*}
    \widehat{u}=\frac{f}{|\tau+\xi^2|^b}
\end{equation*}
If we ignore $\xi$, i.e., $L^2/\tau^b$, and $L^2$ is closed under multiplication of two $L^2$ functions, hence this makes sense as long as $1/\tau^b\in L^2$, i.e. $b<1/2$. This gives an upperbound for $b$. Does there exist a lower bound?

If $b<0$, then $\widehat{u}$ vanishes on $\tau+\xi^2=0$. Hence the worst $f$ you could have is
\begin{equation*}
    f\approx |\tau+\xi^2|^{-\frac{1}{2}+}
\end{equation*}
If the exponent goes below $-1/2$, then $f\not\in L^2$. Hence $b\geq -1/2$.

To sum up, we have two choices: in homogeneous spaces, we require $-1/2<b<1/2$;  in inhomogeneous spaces, there is not restriction. We also consider scaling:
\begin{equation*}
    (i\partial_t+\Delta)u=0, u(0)=u_0\in\dot{H}^s, \Rightarrow \|u\|_{L^\infty\dot{H}^s}
\end{equation*}
Now we ask how does $X^{S,b}$ scale?
\begin{equation*}
    \frac{n+2}{2}-s-2b=\frac{n}{2}-s
\end{equation*}
This gives $b=1/2$.

\begin{remark}
    This is a major downside of Bourgain spaces, since scaling wouldnt' work since $b=1/2$ is not allowed.
\end{remark}
We connect them with the Strichartz spaces.
\begin{equation*}
    S\leftarrow X^{0,1/2}, S^s\leftarrow X^{s,1/2}
\end{equation*}
Hence the dual $S'$ corresponds to the dual $X^{0,-1/2}$.

\begin{remark}
    One could work in Bourgain spaces if they care about resonant interactions, and Strichartz estimates if they don't...
\end{remark}

Now we ask the question, can we find a middle ground between $X^{0,1/2}$ and Strichartz. Note that 
\begin{equation*}
    X^{0,1/2}\subset S, X^{0,0}=L^2
\end{equation*}
We could interpolate in between
\begin{equation*}
    X^{0,b}\subset L^{p_1}L^{q_1}, \text{ where } \frac{1}{p_1}=(1-2b)\frac{1}{2}+2b\frac{1}{p}
\end{equation*}
and the same relation holds for $q$. However, note that $\dot{X}^{0,1/2}\subset S$ is not well-defined. However, the above $X^{0,b}$ is true. Hence, we interpolate, again.

\begin{theorem}
    $X^{s,b}$ to Strichartz embedding holds, where $b\in [0,1/2)$.
\end{theorem}
We would like to prove something like $X^{0,b}\subset L^{p_1}L^{q_1}$, then we look at the map
\begin{equation*}
    u\to\frac{1}{|D_t+D_x^2|^b}u, L^2\to L^{p_1}L^{q_1}
\end{equation*}
\begin{proof}
    We shall do a $TT^*$ argument.
    \begin{equation*}
        Q_b=T_bT_b^*: f\mapsto\frac{1}{|D_t+D_x^2|^{2b}}f
    \end{equation*}
    where $\frac{1}{|D_t+D_x^2|^{2b}}$ is a multiplier, and has a proper symbol in the dual space. And we would want
    \begin{equation*}
        Q_b=TT^*: L^{p_1'}L^{q_1'}\to L^pL^q
    \end{equation*}
    Note that $T: X_0\to Y_0$, and $T: X_1\to Y_1$, then we can interpolate to have $X_\theta\to Y_\theta$. For our purposes, we consider a different interpolation, known as Stein's interpolation (for strips in the complex plane), shown in Figure 8.

    We apply Stein's interpolation. $Re(b)=0$, and $T_b: L^2\to L^2$. $Q_b$, multipliers with symbol: (we would like to extend the range of $b$)
    \begin{equation*}
        \Gamma(2b)=(\tau+\xi^2+i0)^{2b}
    \end{equation*}
    This homogeneous expression does not have constraint on $b$. We can increase $b$ until $q\to\infty$.

    Note homogeneous functions act funny when the exponents are integers, hence we use the Gamma function $\Gamma$ to kill the integers. Then $p_1=q_1$ at endpoint, $p=q=\infty$. Now we just need to bound the Fourier transform of $\tau_\xi^2$
    \begin{equation*}
        Q_b=\ast (\tau+\xi^2)^{2b}: L^1\to L^\infty
    \end{equation*}

\end{proof}


