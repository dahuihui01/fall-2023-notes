\chapter{Introduction}
We will first introduce three questions in incidence geometry: the projection problem, the distance set problem, and the discrete Kakeya problem in $\R^2$. Let $P$ be a discrete subset of $\R^2$.

\begin{problem}[ (Projection)]
    Let $e\in S^1$, and $\pi_e$ be the projection onto the line $l_e$. We ask the upper bound on the number of $e$ such that $\pi_e(P)\leq\frac{n}{8}$, given that $P$ is a discrete set with $|P|=n$. 
\end{problem}
\begin{problem}[ (Distance set)]
    What is the lower bound the distance set $\Delta(P)$
    \begin{equation*}
        \Delta(P)=\{|p-p'|: p,p'\in P\}
    \end{equation*}
\end{problem}
\begin{problem}[ (Discrete Kakeya/Joints problem)]
    Given a set of $m$ lines $\mathcal{L}$, such that each line $l\in\mathcal{L}$ is $m$-rich, i.e.
    \begin{equation*}
        |P\cap l|\geq m \text{ for each } l
    \end{equation*}
    Can we put a lower bound on the size of $P$.
\end{problem}

We remind ourselves of a sharp bound regarding how the lines and points intersect. Let $I(P,\lin)=\{(p,l)\in P\times \lin: p\in l\}$ 
\begin{theorem}[Szemeredi-Trotter theorem]
    For any $P\subset\R^2$, and a finite set of lines, then we have
    \begin{equation*}
        |I(P,\lin)|\lesssim \left(|P||\lin|\right)^\frac{2}{3}+|\lin|+|P|
    \end{equation*}
\end{theorem}
We will prove a weaker result for some intuition, and gain some insight into the projection problem and the discrete Kakeya problem.
\begin{proposition}[Weaker S-T]
    \label{weakst}
    In $\R^2$, we have that
    \begin{equation}
        |I(P,\lin)|\lesssim 4\min\{|P|^\frac{1}{2}|\lin|+|P|, |\lin|^\frac{1}{2}|P|+|\lin|\}
    \end{equation}
\end{proposition}
Using Proposition~\ref{weakst}, we get the following lower bound on the discrete Kakeya problem in $\R^2$.
\begin{corollary}
    we get that for a set of $m$ lines such that each line intersects the point set $P$ at least $m$ times, we get that
    \begin{equation*}
        |P|\gtrsim m^2
    \end{equation*}
\end{corollary}
\begin{note}
    The distance set problem can be realized as intersections between points and circles, instead of points and lines.
\end{note}
We make a similar conjecture in $\R^n$, for $m^{n-1}$ lines such that each line intersects the point set $P$ at least $m$ times, then we should have
\begin{equation*}
    |P|\gtrsim m^n
\end{equation*}
This statement fails for $\R^3$. Yet we could enforce some assumption to push to a nicer result.
\begin{theorem}[G-N, Joints Problem]
    For a set of $m^2$ lines such that no more than $m$ lines lie in the same plane, and each line intersects the point set $P$ at at least $m$ points, then we have
    \begin{equation*}
        |P|\gtrsim m^3
    \end{equation*}
    (This is in fact a conjecture by Bourgain and a corollary to the Joints problem in $\R^3$).
\end{theorem}
We now prove Proposition~\ref{weakst}. \textcolor{red}{unfinished here, the key idea is to use cauchy schwartz to get an $l^2$ norm to interpret as two points. } 

We now give some general bounds on the size of $\Delta(P)$ given that $|P|=n$.
\begin{exercise}
    For a given $n\in\mathbb{N}$, there exists a set $P$ such that $|\Delta(P)|\lesssim n$, for example, the set of $n$ points arranged on a straight line.
\end{exercise}
\begin{exercise}
    We now get some general lower bound on $\Delta(P)$. We can show $|\Delta(P)|\gtrsim n^\frac{1}{2}$. Consider two distinct points $p_1, p_2$, if we show that either
    \begin{equation*}
        |\{|p_1-p|:q\in P\}|\gtrsim n^\frac{1}{2} \text{ or } |\{|p_2-q|: q\in P\}|\gtrsim n^\frac{1}{2}
    \end{equation*}
    WLOG, assume $p_1$ has that
    \begin{equation}\label{circle}
        |\{|p_1-q|: q\in P\}|\lesssim n^\frac{1}{2}
    \end{equation}
    Then we would like to show that
    \begin{equation*}
        |\{|p_2-q|: q\in P\}|\gtrsim n^\frac{1}{2}
    \end{equation*}
    If the equation~\ref{circle} is true, then there exists a distance $r$ such that 
    \begin{equation*}
        |Q|=|\{q\in P:|p_1-q|=r|\}|\gtrsim n^\frac{1}{2}
    \end{equation*}
    And for $p_1\neq p_2$, we have
    \begin{equation*}
        |\{|p_2-q|:q\in Q\}|\gtrsim n^\frac{1}{2}
    \end{equation*}
\end{exercise}

\chapter{Dimensions}
We now discuss some ways of measuring size of fractal sets.
\begin{definition}
    Given a bounded set $E$, we define its $\delta$-covering number $|E|_\delta$ as the smallest number of $\delta$-balls needed to cover $E$.
\end{definition}
We note that as $\delta\to 0$, $|E|_\delta\to\infty$, so does $\frac{1}{\delta}$, hence comparing the rate of increase between the two gives us the Minkowski dimension (box counting dimension).
\begin{example}
    Let $f: (X,d)\to (Y, d')$ is biLipschitz, if there eixts a constant $C$ such that 
    \begin{equation*}
        C^{-1}d'(f(x), f(y))\leq d(x,y)\leq Cd'(f(x), f(y))
    \end{equation*}
    Let $f:[0,1]^n\to\R^n$ be biLipschitz, where $E=f([0,1]^n)$, then we have
    \begin{equation*}
        C^{-1}E\leq |[0,1]^n|\leq CE
    \end{equation*}
    Hence $[0,1]\sim E$, and $|E|_\delta\sim\delta^{-n}$.
\end{example}

\begin{definition}[Upper and Lower Minkowski's dimension]
    Let $E$ be a bounded set in $\R^n$, and $|E|_\delta$ be the $\delta$-covering number, then we define the upper and lower Minkowski dimension as follows:
    \begin{equation*}
        \overline{\dim_B}(E)=\limsup_{\delta\to 0}\frac{\log(|E|_\delta)}{\log(1/\delta)}, \underline{\dim_B}(E)=\liminf_{\delta\to 0}\frac{\log(|E|_\delta)}{\log(1/\delta)}
    \end{equation*}

\end{definition}
\begin{example}\label{exampleQ}
    The countable set $E=\mathbb{Q}
    \cap[0,1]$, has Lebesgue measure 0, and has Minkowski dimension:
    \begin{equation*}
        \dim_B(E)=\lim_{\delta\to 0}\frac{\log(\delta^{-1})}{\log(\delta^{-1})}=1
    \end{equation*}
\end{example}
\begin{example}
    The set $E=\{\frac{1}{n}:n\in\mathbb{N}\}$ has Minkowski dimension: for every $\frac{1}{n}$, it could be covered by a $\delta=n^{-2}$-length disjoint interval, hence
    \begin{equation*}
        \dim_B(E)=\lim_{\delta\to 0}\frac{\log(n)}{\log(n^2)}=\frac{1}{2}
    \end{equation*}
\end{example}
\begin{example}
    The set $E=\{\frac{1}{2^n}: n\in\mathbb{N}\}$ is ``too sparse'' of a fractal so its box counting dimension is the same as the topological dimension.
    \begin{equation*}
        \dim_B(E)=\lim_{\delta\to 0}\frac{\log(n)}{\log(2^n)}=\lim_{n\to\infty}\frac{\log(n)}{n\log(2)}=0
    \end{equation*}
    One could generalize this to get any set $E=\{a^{-n}: n\in\mathbb{N}\}$ has Minkowski dimension 0.
\end{example}
\begin{example}
    The Cantor set, splits into $2^n$ intervals of length $\frac{1}{3^n}$.
    \begin{equation*}
        \dim_B(E)=\lim_{\delta\to0}\frac{\log(2^n)}{\log(3^n)}=\frac{\log(2)}{\log(3)}
    \end{equation*}
\end{example}
\begin{note}
    Minkowski dimension does not always exist if the upper or lower Minkowski dimensions don't agree, and it does not work with unbounded sets $E$.
\end{note}
\begin{note}
    The example~\ref{exampleQ} has Minkowski dimension 1, but it is a countable set, hence we would like to assign it measure 0.
    \begin{equation*}
        \dim\cup_iE_i=\sup_{i}\dim E_i
    \end{equation*}
\end{note}
To address the above two concerns, we introduce the Hausdorff dimension. We do it in three steps: introduce an up-to-$\delta$-cover $\{U_j\}$, construct Hausdorff $\delta$-measure, and letting $\delta\to 0$.
\subsection{Hausdorff measure}
\begin{definition}[$s$-dim Hausdorff measure]
    Fix $s\geq 0$, and $\delta\in(0,\infty]$, given a set $E\in\R^n$, an ``up-to-$\delta$''-cover of $E$ is a \textbf{countable} family of sets $\{U_j\}_{j\in\mathbb{N}}$ such that
    \begin{equation*}
        E\subset\cup_jU_j, diam(U_j)\leq\delta, \text{ for all } j
    \end{equation*}
    And an $s$-dimensional Hausdorff $\delta$-meausre of the set $E$ is
    \begin{equation*}
        H_\delta^s(E)=\inf\left\{\sum_jdiam(U_j)^s, \{U_j\}_j \text{ is an up-to-$\delta$-cover of } E \right\}
    \end{equation*}
    Finally, the $s$-dimensional Hausdorff measure of $E$ is
    \begin{equation*}
        H^s(E)=\lim_{\delta\to 0}H_\delta^s(E)
    \end{equation*}
\end{definition}
\begin{remark}
    The limit is well justified since as $\delta\to 0$, $H_\delta^s(E)$ is an increasing function.
\end{remark}
There are many nice properties regarding the Hausdorff measure, for example, $n$-dim Hausdorff measure agrees with the $n$-dim Lebesgue measure, and there is a unique number such that the Hausdorff measure stops being $\infty$, and equivalently drops to zero. Hence based on this observation, we introduce the Hausdorff dimension of a set $E$.
\begin{definition}[Hausdorff dimension]
    For a set $E\subset\R^n$, we have
    \begin{equation*}
        \dim_H(E)=\sup\{s: H^s(E)=\infty\}=\inf\{s: H^s(E)=0\}
    \end{equation*}
\end{definition}
Before anything, we first check that the $s$-dimensional Hausdorff measure defined above is indeed a measure.
\begin{proposition}
    For $s\geq 0$, the $s$-dimensional measure is indeed a measure.
\end{proposition}
\begin{proof}
    We have that $\mu(\emptyset)=0$, and $\mu(E)\geq 0$ for all $E$. Finally we check the measure is countably additive. For $\{E_j\}_{j\in\mathbb{N}}$ disjoint sets, we consider $E=\cup_jE_j$, as $\delta\to 0$, (or for $\delta$ sufficiently small, given $E_j$'s are disjoint), all the up-to-$\delta$-covers are disjoint, hence
    \begin{equation*}
        H_\delta^s(\cup_jE_j)=\sum_j H_\delta^s(E_j)
    \end{equation*}
    And letting $\delta\to 0$, we get
    \begin{equation*}
        H^s(\cup_jE_j)=\sum_jH^s(E_j)
    \end{equation*}
\end{proof}
\qed

\begin{proposition}
    The following are basic facts about the Hausdorff measure:
    \begin{enumerate}
        \item for $n\in\mathbb{N}$, let $m$ be the $n$-dim Lebesgue measure, there exists a constant $C$ such that
        \begin{equation*}
            C^{-1}H^n(E)\leq m(E)\leq CH^n(E)
        \end{equation*}
        \item $H^s(E)$ is a nonincreasing function of $s$.
        \item For $0\leq s_1<s_2<\infty$
        \begin{equation*}
            \text{either } H^{s_1}(E)=\infty \text{ or } H^{s_2}(E)=0
        \end{equation*}
        \item For $s>n$, and $E\subset\R^n$, we have that
        \begin{equation*}
            H^s(E)=0
        \end{equation*}
        \item For $E\subset\R^n$, and $s\geq 0$, we have that
        \begin{equation*}
            H^s(E)=0 \iff H_\infty^s(E)=0
        \end{equation*}
    \end{enumerate}
\end{proposition}
\begin{example}
    For a set $E\subset\R^n$, we have that the $n$-dimensional Hausdorff measure should agree with the standard Lebesgue measure on $\R^n$. For if $E$ is unbounded, then $m(E)=\infty$, and 
\end{example}


\begin{exercise}
    We have that for $f: A\to R^m, A\subset R^n$, for a fixed $s\geq 0$, and $f$ is Lipschitz with Lipschitz constant $L$, we have that 
    \begin{equation*}
        H^s(f(A))\lesssim_LH^s(A)
    \end{equation*}
\end{exercise}
\begin{proof}
    For any up-to-$\delta$ cover $\{E_j\}$ of $A$, we have $\{f(E_j)\}_j$ is an (up-to-some constant)-$\delta$ cover of $f(A)$, hence 
\end{proof}

\begin{proposition}
    The Hausdorff measure is monotone: for $E_1\subset E_2$, we have that
    \begin{equation*}
        H^s(E_1)\leq H^s(E_2)
    \end{equation*}
\end{proposition}
\begin{proof}
    For $E_1\subset E_2$, for each $\delta$,  an up-to-$\delta$-cover of $E_2$ is also an up-to-$\delta$ cover of $E_1$, and hence taking the infimimum, we get that $H^s(E_1)\leq H^s(E_2)$.
\end{proof}
\qed


\begin{proposition}
    The Hausdorff dimension satisfies that the dimension is a local property:
    \begin{equation*}
        \dim(\cup_jE_j)=\sup_j\dim(E_j)
    \end{equation*}
\end{proposition}
\begin{proof}
    We would like to show that $H^s(\cup_jE_j)=\infty$ if and only if $\sup_jH^s(E_j)=\infty$, and similarly, $H^s(\cup_jE_j)=0$ if and only if $\sup_jH^s(E_j)=0$.

    This is a total of 4 directions. By monotonicity, two directions are shown:
    \begin{equation*}
        \sup_jH^s(E_j)=\infty \Rightarrow H^s(\cup_jE_j)=\infty
    \end{equation*}

    Moreover,
    \begin{equation*}
        H^s(\cup_jE_j)=0\Rightarrow \sup_jH^s(E_j)=0
    \end{equation*}

    Moreover, by $H^s$ being a measure, if we have $\sup_jH^s(E_j)=0$, then all $H^s(E_j)=0$ for all $j$, thus
    \begin{equation*}
        H^s(\cup_jE_j)\leq\sum_jH^s(E_j)=0
    \end{equation*}
    Now it remains to show that \textcolor{red}{what}

\end{proof}


Now we justify the usage of $H^s$, instead of just working $H_\delta^s$.
\begin{exercise}
    For $0\leq s\leq 1, n\geq 2$, we have
    \begin{equation*}
        H_2^s(B_1)=H_2^s(\overline{B_1})=H_2^s(\partial(B_1))
    \end{equation*}
    We see that
    \begin{equation*}
        H_2^s(B)=H_2^s(\overline{B})=2
    \end{equation*}
    Then $H_2^s(\partial B)=0$ if $\overline{B}$ was indeed measurable. But for $0\leq s\leq $, it is more reasonable to cover $\overline{\partial B}$ with bigger covers.
\end{exercise}

Hence we work with $H^s$ to get a Borel regular measure. Recall the following definitions.
\begin{definition}
    A measure $\mu$ is a Borel measure if all Borel sets are $\mu$-measurable. Moreover, $\mu$ is called Borel regular if for any Borel set $A$, there exists another Borel set $B$ such that $B\subset A$, and $\mu(A)=\mu(B)$.
\end{definition}
With our construction, we claim that the Hausdorff measure $H^s$ for any $s>0$ is a Borel regular measure.
\begin{proposition}
    $H_\delta^s$ is a Borel regular measure.
\end{proposition}
\begin{proof}
    We first accept the fact that every Borel set is $H^s$-measurable. We show that $H^s$ is Borel-regular. For a Borel set $A$, we would like to approximate it by ``fattening up'' the covers. For each $n$, let $B_n:=\cup_jE_{n,j}$ be a cover of $A$, and such that $\sum_{j}(diam(E_{n,j}))^s\leq H_\frac{1}{n}^s(A)+\frac{1}{n}$. Then if we take $B=\cap_nB_n$, we have that $A\subset B$, and $H^s(A)=\cap_n H_\frac{1}{n}^s(A)\geq\sum_j(diam(E_{n,j}))^s-\frac{1}{n}\geq \cap_nH_\frac{1}{n}^s(B_n)-\frac{1}{n}$, which by our construction, is $H^s(B)$. Then by monotonicity of $H^s$, we have that
    \begin{equation*}
        H^s(A)=H^s(B)
    \end{equation*}
\end{proof}
\begin{note}
    The countably additivity of $H^s$ comes from the fact that all Borel sets are $H^s$-measurable, and any meausure if countably additive on its measurable sets.
\end{note}

\textcolor{red}{Section 3}
This is part to be typed up. We did Mass distribution principle, which states that if $E$ has that a $r_0$ Frostman measure $\mu$, then $H_{r_0}(E)\geq\mu(E)/C$, and if further we have that $\mu(E)>0$, then $\dim_HE\geq s$.

\begin{enumerate}
    \item Frostman implies positive Hausdorff dimension
    \item definition of support of a measure 
    \item push-forward measure 
\end{enumerate}


This is page 12 on weak convergence of measures.
\begin{definition}[Weak convergence of measures]
    Let $\{\mu_j\}$ be a sequence of locally finite measures (they automatically assign finite measures to all compact sets), and we say $\{\mu_j\}$ converges to $\mu$ weakly if for all $\varphi\in C_c(X)$, we have
    \begin{equation*}
        \lim_{j\to\infty}\int\varphi d\mu_j=\int \varphi d\mu
    \end{equation*}
\end{definition}

Our goal for tonight is to understand the proof of the Frostman Lemma.
\begin{lemma}[Frostman Lemma]
    Assume $E\subset\R^n$ is a compact set with $H^s(E)>0$, then there exists a compactly supported Borel measure $\mu$ with $supp(\mu)\subset E$ and $\mu(E)\gtrsim H_\infty^s(E)$, and such that for all $x\in\R^n, r>0$, we have
    \begin{equation*}
        \mu(B(x,r))\leq r^s
    \end{equation*}
\end{lemma}
\begin{proof}
    
\end{proof}

There are some things we need to establish before the we prove the Frostman lemma. For a set $E\in\R^n$, we use $\mathcal{M}(E)$ to denote the set of finite Borel measures whose support is contained in $E$, i.e. if $\mu\in\mathcal{M}(E)$, we have
\begin{equation*}
    supp(\mu)\subset E, \text{ and }0<\mu(E)<\infty
\end{equation*}

Next we state the ``Bolzano-Weierstrass'' theorem for measures.
\begin{lemma}
    Let $\{\mu_j\}$ be a sequence of locally finite Borel measures on $\R^n$, i.e., for all $K$ compact subset in $\R^n$, we have
    \begin{equation*}
        \sup_{j\in\mathbb{N}}\mu_j(K)<\infty
    \end{equation*}
    Then there exists a subsequence $\mu_{j_k}$ such that as $k\to\infty$, the subsequence converges to $\mu$.
\end{lemma}


\section{Hausdorff dimension of product sets}
\begin{theorem}[Hausdorff dimension of product sets]
    Let $A,B$ be Borel sets, and $s,t\geq 0$, then we have
    \begin{equation*}
        H_\infty^{s+t}(A\times B)\gtrsim_{d_1, d_2}H_\infty^s(A)H_\infty^t(B)
    \end{equation*}
\end{theorem}
\begin{proof}
    We use the theorem that positive Hausdorff meausre if and only if there exists a Frostman measure.
    
    Assume $H_\infty^s(A)>0, H_\infty^t(B)>0$, then there exists $\mu_1, \mu_2$ such that 
    \begin{equation*}
        \mu_1(A)\gtrsim H_\infty^s(A), \mu_2(B)\gtrsim H_\infty^t(B)
    \end{equation*}
    Then we consider any ball $B((x_1, x_2), r)$, we have that
    \begin{equation*}
        B((x_1, x_2), r)\subset B(x_1, r)\times B(x_2, r)
    \end{equation*}
    Hence we have
    \begin{equation*}
        \mu_1\times\mu_2(A\times B)\gtrsim r^{s+t}
    \end{equation*}
    Hence $\mu_1\times\mu_2$ is a Frostman measure on $A\times B$, hence 
    \begin{equation*}
        H_\infty^{s+t}(E)\geq r^{s+t}\gtrsim H_\infty^s(A)H_\infty^t(B)
    \end{equation*}

\end{proof}
\begin{corollary}
    For $A,B$ Borel sets, we have
    \begin{equation*}
        \dim_H(A\times B)\geq \dim_H(A)+\dim_H(B)
    \end{equation*}
\end{corollary}
\begin{proof}
    Once we have $ H_\infty^{s+t}(A\times B)\gtrsim_{d_1, d_2}H_\infty^s(A)H_\infty^t(B)$, it is easy to see, if $\dim_H(A)> s$, and $\dim_H(B)>t$, then we have that $H_\infty^s(A)\geq 0$, and $H_\infty^t(B)\geq 0$, thus $H_\infty^{s+t}(A\times B)\geq 0$, hence we have
    \begin{equation*}
        \dim_H(A\times B)\geq s+t
    \end{equation*}
\end{proof}
\qed

\begin{corollary}
    We also have that
    \begin{equation*}
        \dim_H(A\times B)\leq\dim_HA+\overline{\dim_M}B
    \end{equation*}
\end{corollary}
\begin{proof}
    If we assume that $\dim_H(A)<s, \dim_H(B)\leq\overline{\dim_M}(B)<t$, then we have
    \begin{equation*}
        \dim_H(B)<t, i.e. H_\infty^t(B)=0
    \end{equation*}
    \begin{equation*}
        \dim_\infty(A\times B)
    \end{equation*}
\end{proof}



\section{Riesz Energies}
We revisit the question regarding projections.
Assume $E$ is compact,do we always have
\begin{equation*}
    \dim_H(\pi_e(E))=\min\{\dim_H(E), 1\}
\end{equation*}
for some $e\in S^1$ or for all $e\in S^1$.

The important implication is we would like to transfer an $s$-dimensional Frostman measure on $E$ to an $s$-dimensional Frostman measure(the push-forward measure) on $\pi_e(E)$, i.e. we would like to have if $\mu(B(x,r))\lesssim r^s$ for $supp(\mu)\subset E$,
\begin{equation*}
    \mu_{\pi_e}(B(x,r))\lesssim r^s
\end{equation*}
where $supp(\mu_{\pi_e})\subset \pi_e(E)$.

\begin{definition}[Riesz potential and energy of measures]
    Let $0\leq s\leq d$, and let $\mu$ be a Borel measure on $\R^d$. The $s$-dimensional Riesz potential of the measure $\mu$ at a particular point is
    \begin{equation*}
        V_s(\mu)(x)=\mu\ast k_s(x)=\int\frac{1}{|x-y|^s}d\mu(y)
    \end{equation*}
    where $k_s$ is the $s$-dimensional Riesz kernel 
    \begin{equation*}
        k_s(x)=\frac{1}{|x|^s}
    \end{equation*}
    And the $s$-dimensional Riesz energy of the measure $\mu$ is given by integrating the potential:
    \begin{equation*}
        I_s(\mu)=\int V_s(\mu)d\mu(x)=\int\int\frac{1}{|x-y|^s}d\mu(x)d\mu(y)
    \end{equation*}
\end{definition}

The reason for introducing the Riesz energies and potentials is because they almost carry the same information as a measure being $s$-Frostman.
\begin{proposition}[Finite energy if and only if $s$-Frostman]
    Let $\mu\in M(\R^d)$ be $s$-Frostman, then for all $0\leq t<s$, we have $\|V_t(\mu)\|_\infty<\infty$, and
    \begin{equation*}
        I_t(\mu)<\infty
    \end{equation*}
    Conversely, if we have finite $s$-Riesz energy, $I_s(\mu)<\infty$, then there exists a subset $B\subset\R^d$, that we have
    \begin{equation*}
        \mu(B)>0, \mu\vert_B \text{ is $s$-Frostman}
    \end{equation*}
\end{proposition}
\begin{proof}
    \textcolor{red}{computation, should do this}
\end{proof}

As an immediate corollary, we establish a relationship between finite energy of a measure with positive Hausdorff dimension.
\begin{corollary}[Finite energy and positive Hausdorff measure]
    Let $E\subset\R^d$, then $\dim_H(E)>s\geq0$, then there exists a measure $\mu$ such that $\mu\in M(E)$, and 
    \begin{equation*}
        I_s(\mu)<\infty
    \end{equation*}
    Conversely, if there exists a $\mu\in M(E)$ such that $I_s(E)<\infty$, then we have
    \begin{equation*}
        \dim_H(E)\geq s
    \end{equation*}
\end{corollary}

\begin{note}
    Justifying that the measure has finite energy for $H^1$ almost every $e$ is the strategy for proving Marstrand's projection theorem.
\end{note}
Now we prove the Marstrand's projection theorem.
\begin{theorem}[Marstrand's projection theorem]
    Let $E\subset\R^2$ be Borel, then
    \begin{equation*}
        \dim_H\pi_e(E)=\min\{\dim_H(E), 1\}
    \end{equation*}
    for $H^1$ almost every $e\in S^1$.
\end{theorem}

